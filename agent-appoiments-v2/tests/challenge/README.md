# üî• Tests de Desaf√≠o del Agente

Suite de tests dise√±ados para **retar** al agente de reservas y verificar su robustez en condiciones reales y extremas.

## üìã √çndice de Tests

### ‚úÖ Test 1: Flujos Completos End-to-End
**Archivo:** `test_1_complete_flows.py`

**Objetivo:** Verificar que el agente completa flujos completos sin errores.

**Tests incluidos:**
- ‚úÖ Booking perfecto en espa√±ol
- ‚úÖ Booking perfecto en ingl√©s
- ‚úÖ Cancelaci√≥n con confirmation v√°lido
- üî• Cancelaci√≥n con confirmation inv√°lido (debe escalar despu√©s de 2 intentos)
- ‚úÖ Reprogramaci√≥n completa

**Ejecutar:**
```bash
./run_challenge_tests.sh 1
# O directamente:
pytest tests/challenge/test_1_complete_flows.py -v -s
```

---

### üî• Test 2: Edge Cases y Comportamientos Impredecibles
**Archivo:** `test_2_edge_cases.py`

**Objetivo:** Verificar que el agente maneja comportamientos impredecibles del usuario.

**Tests incluidos:**
- üî• Usuario cambia de opini√≥n a mitad del flujo
- üî• Usuario da toda la info en un mensaje
- üî• Usuario env√≠a gibberish y intentos de injection
- üî• Usuario env√≠a m√∫ltiples mensajes r√°pidamente (double-texting)
- üî• Emails inv√°lidos (validaci√≥n robusta)
- üî• Tel√©fonos inv√°lidos (validaci√≥n robusta)
- üî• Fechas l√≠mite (pasado, futuro lejano)

**Ejecutar:**
```bash
./run_challenge_tests.sh 2
# O directamente:
pytest tests/challenge/test_2_edge_cases.py -v -s
```

---

### ‚ö° Test 3: Concurrencia y Carga
**Archivo:** `test_3_concurrency.py`

**Objetivo:** Verificar que el agente maneja m√∫ltiples usuarios simult√°neos.

**Tests incluidos:**
- ‚úÖ 5 usuarios concurrentes (carga ligera)
- üî• 10 usuarios concurrentes (carga media)
- üî•üî• 20 usuarios concurrentes (carga alta)
- ‚úÖ 10 usuarios secuenciales (carga realista)

**M√©tricas evaluadas:**
- Success rate (>=80%)
- Tiempo promedio (<90s)
- Tiempo m√°ximo (<150s)
- Desviaci√≥n est√°ndar

**Ejecutar:**
```bash
./run_challenge_tests.sh 3
# O directamente:
pytest tests/challenge/test_3_concurrency.py -v -s
```

---

### üõ°Ô∏è Test 4: Resiliencia y Manejo de Errores
**Archivo:** `test_4_resilience.py`

**Objetivo:** Verificar que el agente maneja errores y se recupera correctamente.

**Tests incluidos:**
- üî• API no disponible (graceful degradation)
- üî• Timeout de API (retry logic)
- üî• Estado inv√°lido (recovery)
- üî• Conversaci√≥n larga (sliding window)
- üî• Cambios r√°pidos entre threads
- üî• Intentos de prompt injection
- üî• Datos con caracteres especiales

**Ejecutar:**
```bash
./run_challenge_tests.sh 4
# O directamente:
pytest tests/challenge/test_4_resilience.py -v -s
```

---

## üöÄ Ejecuci√≥n R√°pida

### Ejecutar TODOS los tests:
```bash
./run_challenge_tests.sh all
# O simplemente:
./run_challenge_tests.sh
```

### Ejecutar un test espec√≠fico:
```bash
./run_challenge_tests.sh 1   # Solo Test 1
./run_challenge_tests.sh 2   # Solo Test 2
./run_challenge_tests.sh 3   # Solo Test 3
./run_challenge_tests.sh 4   # Solo Test 4
```

### Ejecutar con pytest directamente:
```bash
# Ejecutar todo con output detallado
pytest tests/challenge/ -v -s

# Ejecutar solo un archivo
pytest tests/challenge/test_1_complete_flows.py -v -s

# Ejecutar un test espec√≠fico
pytest tests/challenge/test_1_complete_flows.py::TestCompleteBookingFlows::test_perfect_booking_flow_spanish -v -s

# Ejecutar en paralelo (requiere pytest-xdist)
pytest tests/challenge/ -n auto
```

---

## üìä Interpretaci√≥n de Resultados

### ‚úÖ S√≠mbolos
- ‚úÖ **Test pasa** - El agente cumple los criterios
- ‚ùå **Test falla** - El agente no cumple los criterios
- üî• **Test de estr√©s** - Dise√±ado para ser dif√≠cil

### üìà M√©tricas Clave

**Success Rate:**
- ‚úÖ ‚â•90%: Excelente
- ‚ö†Ô∏è 80-90%: Aceptable
- ‚ùå <80%: Requiere mejoras

**Tiempo Promedio:**
- ‚úÖ <60s: Excelente
- ‚ö†Ô∏è 60-90s: Aceptable
- ‚ùå >90s: Requiere optimizaci√≥n

**Concurrencia:**
- ‚úÖ 10+ usuarios sin degradaci√≥n: Listo para producci√≥n
- ‚ö†Ô∏è 5-10 usuarios: Uso limitado
- ‚ùå <5 usuarios: Solo desarrollo

---

## üîß Requisitos

### Dependencias:
```bash
pip install pytest pytest-asyncio
```

### Servicios necesarios:
1. **Mock API** debe estar corriendo:
   ```bash
   python mock_api.py
   ```

2. **LangGraph** (opcional, solo para Studio):
   ```bash
   langgraph dev
   ```

---

## üéØ Criterios de √âxito para MVP

Para considerar el agente **listo para MVP**, debe cumplir:

- [ ] **Test 1:** 100% de flujos completos pasan
- [ ] **Test 2:** ‚â•80% de edge cases manejados
- [ ] **Test 3:** Soporta ‚â•10 usuarios concurrentes con success rate ‚â•80%
- [ ] **Test 4:** Maneja errores sin crashear (100% recovery)

---

## üêõ Troubleshooting

### Error: "No se pudo crear booking para fixture"
- **Causa:** Mock API no est√° corriendo o tiene datos corruptos
- **Soluci√≥n:** Reiniciar `python mock_api.py`

### Error: "Connection refused"
- **Causa:** Puerto 5000 no disponible
- **Soluci√≥n:** Verificar que Mock API est√° corriendo

### Tests muy lentos
- **Causa:** M√∫ltiples llamadas a API sin cache
- **Soluci√≥n:** Verificar que el cache est√° habilitado en `src/cache.py`

### Success rate bajo en concurrencia
- **Causa:** MemorySaver no es thread-safe
- **Soluci√≥n:** Esperado con MemorySaver, PostgreSQL lo resolver√≠a

---

## üìù Notas de Desarrollo

### Limitaciones conocidas con MemorySaver:
- No es thread-safe (esperado en tests de concurrencia)
- Estado se pierde al reiniciar proceso
- No adecuado para producci√≥n distribuida

### Mejoras futuras:
- Agregar tests de latencia TTFT
- Tests de memory leaks
- Tests de degradaci√≥n sostenida
- Integraci√≥n con m√©tricas de LangSmith

---

## üìû Soporte

Si encuentras problemas con los tests:
1. Verificar que Mock API est√° corriendo
2. Verificar versiones de dependencias (`pip list | grep pytest`)
3. Revisar logs en `tests/challenge/pytest.log` (si existe)

**Reporte de bugs:** Incluir output completo de pytest con `-v -s`
